{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Visual C++ Redistributable is not installed, this may lead to the DLL load failure.\n",
      "                 It can be downloaded at https://aka.ms/vs/16/release/vc_redist.x64.exe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    # 本函数生成0-9，10个数字的图片矩阵\n",
    "    image_data = []\n",
    "    num_0 = torch.tensor(\n",
    "        [[0, 0, 1, 1, 0, 0],\n",
    "         [0, 1, 0, 0, 1, 0],\n",
    "         [0, 1, 0, 0, 1, 0],\n",
    "         [0, 1, 0, 0, 1, 0],\n",
    "         [0, 0, 1, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0]])\n",
    "    image_data.append(num_0)\n",
    "    num_1 = torch.tensor(\n",
    "        [[0, 0, 0, 1, 0, 0],\n",
    "         [0, 0, 1, 1, 0, 0],\n",
    "         [0, 0, 0, 1, 0, 0],\n",
    "         [0, 0, 0, 1, 0, 0],\n",
    "         [0, 0, 1, 1, 1, 0],\n",
    "         [0, 0, 0, 0, 0, 0]])\n",
    "    image_data.append(num_1)\n",
    "    num_2 = torch.tensor(\n",
    "        [[0, 0, 1, 1, 0, 0],\n",
    "         [0, 1, 0, 0, 1, 0],\n",
    "         [0, 0, 0, 1, 0, 0],\n",
    "         [0, 0, 1, 0, 0, 0],\n",
    "         [0, 1, 1, 1, 1, 0],\n",
    "         [0, 0, 0, 0, 0, 0]])\n",
    "    image_data.append(num_2)\n",
    "    num_3 = torch.tensor(\n",
    "        [[0, 0, 1, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 1, 0],\n",
    "         [0, 0, 1, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 1, 0],\n",
    "         [0, 0, 1, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0]])\n",
    "    image_data.append(num_3)\n",
    "    num_4 = torch.tensor(\n",
    "        [\n",
    "            [0, 0, 0, 0, 1, 0],\n",
    "            [0, 0, 0, 1, 1, 0],\n",
    "            [0, 0, 1, 0, 1, 0],\n",
    "            [0, 1, 1, 1, 1, 1],\n",
    "            [0, 0, 0, 0, 1, 0],\n",
    "            [0, 0, 0, 0, 0, 0]])\n",
    "    image_data.append(num_4)\n",
    "    num_5 = torch.tensor(\n",
    "        [\n",
    "            [0, 1, 1, 1, 0, 0],\n",
    "            [0, 1, 0, 0, 0, 0],\n",
    "            [0, 1, 1, 1, 0, 0],\n",
    "            [0, 0, 0, 0, 1, 0],\n",
    "            [0, 1, 1, 1, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0]])\n",
    "    image_data.append(num_5)\n",
    "    num_6 = torch.tensor(\n",
    "        [[0, 0, 1, 1, 0, 0],\n",
    "         [0, 1, 0, 0, 0, 0],\n",
    "         [0, 1, 1, 1, 0, 0],\n",
    "         [0, 1, 0, 0, 1, 0],\n",
    "         [0, 0, 1, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0]])\n",
    "    image_data.append(num_6)\n",
    "    num_7 = torch.tensor(\n",
    "        [\n",
    "            [0, 1, 1, 1, 1, 0],\n",
    "            [0, 0, 0, 0, 1, 0],\n",
    "            [0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0]])\n",
    "    image_data.append(num_7)\n",
    "    num_8 = torch.tensor(\n",
    "        [[0, 0, 1, 1, 0, 0],\n",
    "         [0, 1, 0, 0, 1, 0],\n",
    "         [0, 0, 1, 1, 0, 0],\n",
    "         [0, 1, 0, 0, 1, 0],\n",
    "         [0, 0, 1, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0]])\n",
    "    image_data.append(num_8)\n",
    "    num_9 = torch.tensor(\n",
    "        [[0, 0, 1, 1, 1, 0],\n",
    "         [0, 1, 0, 0, 1, 0],\n",
    "         [0, 0, 1, 1, 1, 0],\n",
    "         [0, 1, 0, 0, 1, 0],\n",
    "         [0, 0, 0, 0, 1, 0],\n",
    "         [0, 0, 0, 0, 0, 0]])\n",
    "    image_data.append(num_9)\n",
    "    image_label = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    return image_data, image_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(x):\n",
    "    # dx\n",
    "    def s_x(img):\n",
    "        kernel = np.array([[-1, 0, 1]])\n",
    "        imgx = signal.convolve2d(img, kernel, boundary='symm', mode='same')\n",
    "        return imgx\n",
    "\n",
    "    # dy\n",
    "    def s_y(img):\n",
    "        kernel = np.array([[-1, 0, 1]]).T\n",
    "        imgy = signal.convolve2d(img, kernel, boundary='symm', mode='same')\n",
    "        return imgy\n",
    "\n",
    "    # 模长\n",
    "    def grad(img):\n",
    "        imgx = s_x(img)\n",
    "        imgy = s_y(img)\n",
    "        s = np.sqrt(imgx ** 2 + imgy ** 2)\n",
    "        theta = np.arctan2(imgx, imgy)\n",
    "        # 显示角度值\n",
    "        theta = np.degrees(theta)\n",
    "        theta[theta < 0] = np.pi + theta[theta < 0]\n",
    "        return s, theta\n",
    "\n",
    "    height, width = x.shape\n",
    "    gradient_magnitude, gradient_angle = grad(x)\n",
    "    # cell 6*6\n",
    "    cell_size = 6\n",
    "    # 360°分8份\n",
    "    bin_size = 8\n",
    "    # 分成8份，每一份的度数\n",
    "    angle_unit = 360 / bin_size\n",
    "    # 取模长的绝对值\n",
    "    gradient_magnitude = abs(gradient_magnitude)\n",
    "    # 整张图片对应多少个cell\n",
    "    cell_gradient_vector = np.zeros((int(height / cell_size), int(width / cell_size), bin_size))\n",
    "\n",
    "    # 每个cell的特征\n",
    "    def cell_gradient(cell_magnitude, cell_angle):\n",
    "        # 建立一个全零的cell的特征向量\n",
    "        orientation_centers = [0] * bin_size\n",
    "        # cell是6*6的，遍历每一个像素点\n",
    "        for k in range(cell_magnitude.shape[0]):\n",
    "            for l in range(cell_magnitude.shape[1]):\n",
    "                # 对应的这个像素点的模长\n",
    "                gradient_strength = cell_magnitude[k][l]\n",
    "                # 对应的这个像素点的角度\n",
    "                gradient_angle = cell_angle[k][l]\n",
    "                # 角度值除以均分的每一部分的度数，整数部分是几就在第几个bin中\n",
    "                angle = int(gradient_angle / angle_unit)\n",
    "                # 将模长放入对应的bin中，每个bin的值不断累加更新\n",
    "                orientation_centers[angle] = orientation_centers[angle] + gradient_strength\n",
    "        # 返回cell的特征向量\n",
    "        return orientation_centers\n",
    "\n",
    "    # 遍历所有cell\n",
    "    for i in range(cell_gradient_vector.shape[0]):\n",
    "        for j in range(cell_gradient_vector.shape[1]):\n",
    "            # 取出图片上对应cell的模长\n",
    "            cell_magnitude = gradient_magnitude[i * cell_size:(i + 1) * cell_size,\n",
    "                             j * cell_size:(j + 1) * cell_size]\n",
    "            # 取出图片上对应cell的角度\n",
    "            cell_angle = gradient_angle[i * cell_size:(i + 1) * cell_size,\n",
    "                         j * cell_size:(j + 1) * cell_size]\n",
    "            # 将所有cell的特征向量串到一起\n",
    "            cell_gradient_vector[i][j] = cell_gradient(cell_magnitude, cell_angle)\n",
    "\n",
    "    return cell_gradient_vector\n",
    "\n",
    "\n",
    "def bin2gray(x):\n",
    "    # 将二值化的图像转换为灰度图\n",
    "    gray_img = (x * 255).numpy().astype(np.uint8)\n",
    "    # 对图像使用最近邻方法做resize, 固定图片大小为256\n",
    "    gray_img = cv2.resize(gray_img, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "    return gray_img\n",
    "\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # 这边将reuqires_grad=True用来标记需要自动求导的位置\n",
    "        self.weights = torch.nn.Parameter(torch.DoubleTensor(in_dim, out_dim), requires_grad=True)\n",
    "        nn.init.xavier_uniform_(self.weights)\n",
    "        self.bias = torch.nn.Parameter(torch.DoubleTensor(out_dim), requires_grad=True)\n",
    "        nn.init.zeros_(self.bias)\n",
    "    # 前向计算\n",
    "    def forward(self, input):\n",
    "        return torch.mm(input.view(1, -1), self.weights) + self.bias\n",
    "\n",
    "\n",
    "def train_model(model, data, label, max_epoch=5000, lr=0.001, device='cuda'):\n",
    "    optimizer = torch.optim.SGD([{'params': model.parameters()}], lr=lr)\n",
    "    loss_items = []\n",
    "    for epoch in range(max_epoch):\n",
    "        loss = 0\n",
    "        # 梯度清零，不清零梯度会累加\n",
    "        for img, lbl in zip(data, label):\n",
    "            optimizer.zero_grad()\n",
    "            feat = get_feature(img)\n",
    "            feat = torch.from_numpy(feat).to(device)\n",
    "            y_pred = model(feat)\n",
    "            # l2 distance\n",
    "            loss += 0.5 * (y_pred - lbl) ** 2\n",
    "        # 自动计算梯度\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        print('[Epoch] {}, [Loss] {}'.format(epoch, loss.item()))\n",
    "        loss_items.append(loss.item())\n",
    "\n",
    "    # 绘制loss曲线图\n",
    "    x = np.arange(0, max_epoch)\n",
    "    plt.plot(x, loss_items, color='red', linewidth=1)\n",
    "\n",
    "    plt.title(\"Epoch-Loss Curve\")\n",
    "    plt.savefig(\"./loss.png\")\n",
    "    print(\"loss曲线图已保存到loss.png文件\")\n",
    "\n",
    "# 根据特征预测图片\n",
    "def inference(feat, model, device='cuda'):\n",
    "    return model(torch.from_numpy(feat).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch] 0, [Loss] 60909.69253908813\n",
      "[Epoch] 1, [Loss] 47244.692247165454\n",
      "[Epoch] 2, [Loss] 39332.19758305777\n",
      "[Epoch] 3, [Loss] 33285.52749283271\n",
      "[Epoch] 4, [Loss] 28373.86767610501\n",
      "[Epoch] 5, [Loss] 24323.009407965128\n",
      "[Epoch] 6, [Loss] 20957.631031317884\n",
      "[Epoch] 7, [Loss] 18145.70642784922\n",
      "[Epoch] 8, [Loss] 15784.051515052306\n",
      "[Epoch] 9, [Loss] 13791.016684547922\n",
      "[Epoch] 10, [Loss] 12101.47488179776\n",
      "[Epoch] 11, [Loss] 10663.115529258152\n",
      "[Epoch] 12, [Loss] 9433.650268822228\n",
      "[Epoch] 13, [Loss] 8378.686415783452\n",
      "[Epoch] 14, [Loss] 7470.096062714796\n",
      "[Epoch] 15, [Loss] 6684.755955810381\n",
      "[Epoch] 16, [Loss] 6003.566652728337\n",
      "[Epoch] 17, [Loss] 5410.683516864536\n",
      "[Epoch] 18, [Loss] 4892.909535243237\n",
      "[Epoch] 19, [Loss] 4439.212646086818\n",
      "[Epoch] 20, [Loss] 4040.3395577039196\n",
      "[Epoch] 21, [Loss] 3688.5048797401887\n",
      "[Epoch] 22, [Loss] 3377.1394477346767\n",
      "[Epoch] 23, [Loss] 3100.685487160322\n",
      "[Epoch] 24, [Loss] 2854.4290821762056\n",
      "[Epoch] 25, [Loss] 2634.362538477275\n",
      "[Epoch] 26, [Loss] 2437.070840782441\n",
      "[Epoch] 27, [Loss] 2259.637635819684\n",
      "[Epoch] 28, [Loss] 2099.567117606653\n",
      "[Epoch] 29, [Loss] 1954.718924106938\n",
      "[Epoch] 30, [Loss] 1823.2537250776843\n",
      "[Epoch] 31, [Loss] 1703.5876287162093\n",
      "[Epoch] 32, [Loss] 1594.353888316305\n",
      "[Epoch] 33, [Loss] 1494.3706711083555\n",
      "[Epoch] 34, [Loss] 1402.6138760225874\n",
      "[Epoch] 35, [Loss] 1318.194167608519\n",
      "[Epoch] 36, [Loss] 1240.337539173896\n",
      "[Epoch] 37, [Loss] 1168.368836605568\n",
      "[Epoch] 38, [Loss] 1101.6977708963307\n",
      "[Epoch] 39, [Loss] 1039.8070264812318\n",
      "[Epoch] 40, [Loss] 982.2421374955209\n",
      "[Epoch] 41, [Loss] 928.602857694308\n",
      "[Epoch] 42, [Loss] 878.535794154209\n",
      "[Epoch] 43, [Loss] 831.7281117101318\n",
      "[Epoch] 44, [Loss] 787.9021457299932\n",
      "[Epoch] 45, [Loss] 746.8107863959759\n",
      "[Epoch] 46, [Loss] 708.2335190315073\n",
      "[Epoch] 47, [Loss] 671.9730229139842\n",
      "[Epoch] 48, [Loss] 637.8522460332325\n",
      "[Epoch] 49, [Loss] 605.7118858805668\n",
      "[Epoch] 50, [Loss] 575.40821698079\n",
      "[Epoch] 51, [Loss] 546.8112148380692\n",
      "[Epoch] 52, [Loss] 519.8029335283595\n",
      "[Epoch] 53, [Loss] 494.2761005616487\n",
      "[Epoch] 54, [Loss] 470.13289804391536\n",
      "[Epoch] 55, [Loss] 447.28390374806605\n",
      "[Epoch] 56, [Loss] 425.64716958521336\n",
      "[Epoch] 57, [Loss] 405.14741826258904\n",
      "[Epoch] 58, [Loss] 385.71534171248265\n",
      "[Epoch] 59, [Loss] 367.286987255642\n",
      "[Epoch] 60, [Loss] 349.80321948669814\n",
      "[Epoch] 61, [Loss] 333.2092475926866\n",
      "[Epoch] 62, [Loss] 317.45420928439734\n",
      "[Epoch] 63, [Loss] 302.49080377309775\n",
      "[Epoch] 64, [Loss] 288.2749672939908\n",
      "[Epoch] 65, [Loss] 274.76558559117177\n",
      "[Epoch] 66, [Loss] 261.92423855896675\n",
      "[Epoch] 67, [Loss] 249.71497290231363\n",
      "[Epoch] 68, [Loss] 238.10409925019718\n",
      "[Epoch] 69, [Loss] 227.06001064549406\n",
      "[Epoch] 70, [Loss] 216.55301975427778\n",
      "[Epoch] 71, [Loss] 206.55521249746138\n",
      "[Epoch] 72, [Loss] 197.04031611658863\n",
      "[Epoch] 73, [Loss] 187.98357995114583\n",
      "[Epoch] 74, [Loss] 179.3616674328071\n",
      "[Epoch] 75, [Loss] 171.15255799853878\n",
      "[Epoch] 76, [Loss] 163.33545779343066\n",
      "[Epoch] 77, [Loss] 155.8907181800525\n",
      "[Epoch] 78, [Loss] 148.79976119653557\n",
      "[Epoch] 79, [Loss] 142.0450112144059\n",
      "[Epoch] 80, [Loss] 135.60983214075017\n",
      "[Epoch] 81, [Loss] 129.4784695904682\n",
      "[Epoch] 82, [Loss] 123.63599752458458\n",
      "[Epoch] 83, [Loss] 118.06826891143356\n",
      "[Epoch] 84, [Loss] 112.76187002030753\n",
      "[Epoch] 85, [Loss] 107.70407800298686\n",
      "[Epoch] 86, [Loss] 102.88282145854286\n",
      "[Epoch] 87, [Loss] 98.28664371131549\n",
      "[Epoch] 88, [Loss] 93.90466856242118\n",
      "[Epoch] 89, [Loss] 89.72656830142988\n",
      "[Epoch] 90, [Loss] 85.74253378794687\n",
      "[Epoch] 91, [Loss] 81.94324643307235\n",
      "[Epoch] 92, [Loss] 78.31985192837939\n",
      "[Epoch] 93, [Loss] 74.86393558561929\n",
      "[Epoch] 94, [Loss] 71.56749916404445\n",
      "[Epoch] 95, [Loss] 68.42293907425292\n",
      "[Epoch] 96, [Loss] 65.42302585814953\n",
      "[Epoch] 97, [Loss] 62.56088485394519\n",
      "[Epoch] 98, [Loss] 59.829977963509755\n",
      "[Epoch] 99, [Loss] 57.22408644675056\n",
      "[Epoch] 100, [Loss] 54.73729467427782\n",
      "[Epoch] 101, [Loss] 52.36397477545912\n",
      "[Epoch] 102, [Loss] 50.09877212424212\n",
      "[Epoch] 103, [Loss] 47.9365916097723\n",
      "[Epoch] 104, [Loss] 45.872584643038195\n",
      "[Epoch] 105, [Loss] 43.90213685460347\n",
      "[Epoch] 106, [Loss] 42.02085644182045\n",
      "[Epoch] 107, [Loss] 40.224563127066645\n",
      "[Epoch] 108, [Loss] 38.50927769129355\n",
      "[Epoch] 109, [Loss] 36.87121204972089\n",
      "[Epoch] 110, [Loss] 35.306759838788544\n",
      "[Epoch] 111, [Loss] 33.81248748561287\n",
      "[Epoch] 112, [Loss] 32.3851257330849\n",
      "[Epoch] 113, [Loss] 31.021561595492887\n",
      "[Epoch] 114, [Loss] 29.71883072118182\n",
      "[Epoch] 115, [Loss] 28.474110140245532\n",
      "[Epoch] 116, [Loss] 27.284711376573224\n",
      "[Epoch] 117, [Loss] 26.148073904885745\n",
      "[Epoch] 118, [Loss] 25.061758934497668\n",
      "[Epoch] 119, [Loss] 24.023443502684565\n",
      "[Epoch] 120, [Loss] 23.03091486148237\n",
      "[Epoch] 121, [Loss] 22.08206514269474\n",
      "[Epoch] 122, [Loss] 21.174886286770437\n",
      "[Epoch] 123, [Loss] 20.307465221976752\n",
      "[Epoch] 124, [Loss] 19.47797928109513\n",
      "[Epoch] 125, [Loss] 18.684691843529066\n",
      "[Epoch] 126, [Loss] 17.925948191403158\n",
      "[Epoch] 127, [Loss] 17.200171568847082\n",
      "[Epoch] 128, [Loss] 16.50585943420648\n",
      "[Epoch] 129, [Loss] 15.841579895528403\n",
      "[Epoch] 130, [Loss] 15.205968320104281\n",
      "[Epoch] 131, [Loss] 14.597724109423911\n",
      "[Epoch] 132, [Loss] 14.01560763125258\n",
      "[Epoch] 133, [Loss] 13.458437301057035\n",
      "[Epoch] 134, [Loss] 12.925086805353617\n",
      "[Epoch] 135, [Loss] 12.414482459953048\n",
      "[Epoch] 136, [Loss] 11.925600696438952\n",
      "[Epoch] 137, [Loss] 11.45746567055166\n",
      "[Epoch] 138, [Loss] 11.009146986464915\n",
      "[Epoch] 139, [Loss] 10.579757531262711\n",
      "[Epoch] 140, [Loss] 10.168451414194223\n",
      "[Epoch] 141, [Loss] 9.774422005566988\n",
      "[Epoch] 142, [Loss] 9.396900070395349\n",
      "[Epoch] 143, [Loss] 9.035151992163714\n",
      "[Epoch] 144, [Loss] 8.68847808229489\n",
      "[Epoch] 145, [Loss] 8.356210971134974\n",
      "[Epoch] 146, [Loss] 8.037714076480556\n",
      "[Epoch] 147, [Loss] 7.732380145853095\n",
      "[Epoch] 148, [Loss] 7.4396298689383995\n",
      "[Epoch] 149, [Loss] 7.158910556763172\n",
      "[Epoch] 150, [Loss] 6.889694884367828\n",
      "[Epoch] 151, [Loss] 6.631479693877328\n",
      "[Epoch] 152, [Loss] 6.3837848550473755\n",
      "[Epoch] 153, [Loss] 6.1461521804797705\n",
      "[Epoch] 154, [Loss] 5.9181443928612385\n",
      "[Epoch] 155, [Loss] 5.699344141698556\n",
      "[Epoch] 156, [Loss] 5.489353067150317\n",
      "[Epoch] 157, [Loss] 5.287790908665987\n",
      "[Epoch] 158, [Loss] 5.094294656278206\n",
      "[Epoch] 159, [Loss] 4.908517742462599\n",
      "[Epoch] 160, [Loss] 4.730129272610832\n",
      "[Epoch] 161, [Loss] 4.558813292257178\n",
      "[Epoch] 162, [Loss] 4.39426808926542\n",
      "[Epoch] 163, [Loss] 4.236205529298446\n",
      "[Epoch] 164, [Loss] 4.084350422956099\n",
      "[Epoch] 165, [Loss] 3.938439923060251\n",
      "[Epoch] 166, [Loss] 3.7982229506201075\n",
      "[Epoch] 167, [Loss] 3.6634596481073327\n",
      "[Epoch] 168, [Loss] 3.5339208587136435\n",
      "[Epoch] 169, [Loss] 3.4093876303461736\n",
      "[Epoch] 170, [Loss] 3.289650743162033\n",
      "[Epoch] 171, [Loss] 3.1745102595175223\n",
      "[Epoch] 172, [Loss] 3.063775095244586\n",
      "[Epoch] 173, [Loss] 2.957262611231511\n",
      "[Epoch] 174, [Loss] 2.8547982243368653\n",
      "[Epoch] 175, [Loss] 2.7562150366983467\n",
      "[Epoch] 176, [Loss] 2.661353482558112\n",
      "[Epoch] 177, [Loss] 2.570060991768635\n",
      "[Epoch] 178, [Loss] 2.482191669162908\n",
      "[Epoch] 179, [Loss] 2.3976059890489543\n",
      "[Epoch] 180, [Loss] 2.3161705040851044\n",
      "[Epoch] 181, [Loss] 2.2377575678594246\n",
      "[Epoch] 182, [Loss] 2.162245070508742\n",
      "[Epoch] 183, [Loss] 2.089516186760324\n",
      "[Epoch] 184, [Loss] 2.019459135795071\n",
      "[Epoch] 185, [Loss] 1.9519669523718497\n",
      "[Epoch] 186, [Loss] 1.8869372686751948\n",
      "[Epoch] 187, [Loss] 1.8242721063660383\n",
      "[Epoch] 188, [Loss] 1.763877678363027\n",
      "[Epoch] 189, [Loss] 1.7056641998758775\n",
      "[Epoch] 190, [Loss] 1.64954570825766\n",
      "[Epoch] 191, [Loss] 1.5954398912543206\n",
      "[Epoch] 192, [Loss] 1.543267923250753\n",
      "[Epoch] 193, [Loss] 1.4929543091333386\n",
      "[Epoch] 194, [Loss] 1.4444267354069824\n",
      "[Epoch] 195, [Loss] 1.397615928221948\n",
      "[Epoch] 196, [Loss] 1.3524555179809237\n",
      "[Epoch] 197, [Loss] 1.3088819102154492\n",
      "[Epoch] 198, [Loss] 1.2668341624366581\n",
      "[Epoch] 199, [Loss] 1.226253866669586\n",
      "[Epoch] 200, [Loss] 1.1870850374117896\n",
      "[Epoch] 201, [Loss] 1.1492740047528756\n",
      "[Epoch] 202, [Loss] 1.1127693124100209\n",
      "[Epoch] 203, [Loss] 1.0775216204557385\n",
      "[Epoch] 204, [Loss] 1.0434836125048976\n",
      "[Epoch] 205, [Loss] 1.0106099071592338\n",
      "[Epoch] 206, [Loss] 0.9788569735046841\n",
      "[Epoch] 207, [Loss] 0.9481830504727657\n",
      "[Epoch] 208, [Loss] 0.9185480698806091\n",
      "[Epoch] 209, [Loss] 0.8899135829825257\n",
      "[Epoch] 210, [Loss] 0.8622426903609787\n",
      "[Epoch] 211, [Loss] 0.8354999750075954\n",
      "[Epoch] 212, [Loss] 0.8096514384378327\n",
      "[Epoch] 213, [Loss] 0.7846644397027246\n",
      "[Epoch] 214, [Loss] 0.7605076371584824\n",
      "[Epoch] 215, [Loss] 0.7371509328670528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch] 216, [Loss] 0.7145654195030983\n",
      "[Epoch] 217, [Loss] 0.6927233296514997\n",
      "[Epoch] 218, [Loss] 0.6715979873848765\n",
      "[Epoch] 219, [Loss] 0.651163762012019\n",
      "[Epoch] 220, [Loss] 0.6313960238996285\n",
      "[Epoch] 221, [Loss] 0.6122711022682492\n",
      "[Epoch] 222, [Loss] 0.5937662448725868\n",
      "[Epoch] 223, [Loss] 0.5758595794785315\n",
      "[Epoch] 224, [Loss] 0.5585300770520509\n",
      "[Epoch] 225, [Loss] 0.5417575165838295\n",
      "[Epoch] 226, [Loss] 0.5255224514708122\n",
      "[Epoch] 227, [Loss] 0.5098061773852981\n",
      "[Epoch] 228, [Loss] 0.4945907015614182\n",
      "[Epoch] 229, [Loss] 0.479858713435294\n",
      "[Epoch] 230, [Loss] 0.46559355657458346\n",
      "[Epoch] 231, [Loss] 0.45177920184003895\n",
      "[Epoch] 232, [Loss] 0.4384002217222182\n",
      "[Epoch] 233, [Loss] 0.4254417657989234\n",
      "[Epoch] 234, [Loss] 0.4128895372620849\n",
      "[Epoch] 235, [Loss] 0.4007297704663464\n",
      "[Epoch] 236, [Loss] 0.3889492094517976\n",
      "[Epoch] 237, [Loss] 0.37753508739703506\n",
      "[Epoch] 238, [Loss] 0.3664751069589713\n",
      "[Epoch] 239, [Loss] 0.35575742146152994\n",
      "[Epoch] 240, [Loss] 0.34537061689302645\n",
      "[Epoch] 241, [Loss] 0.3353036946747721\n",
      "[Epoch] 242, [Loss] 0.32554605516976176\n",
      "[Epoch] 243, [Loss] 0.31608748189280234\n",
      "[Epoch] 244, [Loss] 0.3069181263959074\n",
      "[Epoch] 245, [Loss] 0.29802849379351193\n",
      "[Epoch] 246, [Loss] 0.28940942890336463\n",
      "[Epoch] 247, [Loss] 0.281052102972225\n",
      "[Epoch] 248, [Loss] 0.27294800096183786\n",
      "[Epoch] 249, [Loss] 0.26508890936937757\n",
      "[Epoch] 250, [Loss] 0.25746690455974575\n",
      "[Epoch] 251, [Loss] 0.25007434158437114\n",
      "[Epoch] 252, [Loss] 0.2429038434691309\n",
      "[Epoch] 253, [Loss] 0.23594829094557512\n",
      "[Epoch] 254, [Loss] 0.2292008126104897\n",
      "[Epoch] 255, [Loss] 0.22265477549118595\n",
      "[Epoch] 256, [Loss] 0.21630377600145978\n",
      "[Epoch] 257, [Loss] 0.2101416312689297\n",
      "[Epoch] 258, [Loss] 0.20416237081882796\n",
      "[Epoch] 259, [Loss] 0.1983602285982113\n",
      "[Epoch] 260, [Loss] 0.19272963532540516\n",
      "[Epoch] 261, [Loss] 0.18726521115077815\n",
      "[Epoch] 262, [Loss] 0.18196175861566077\n",
      "[Epoch] 263, [Loss] 0.17681425589555552\n",
      "[Epoch] 264, [Loss] 0.17181785031601488\n",
      "[Epoch] 265, [Loss] 0.16696785212987186\n",
      "[Epoch] 266, [Loss] 0.1622597285427598\n",
      "[Epoch] 267, [Loss] 0.15768909797849695\n",
      "[Epoch] 268, [Loss] 0.15325172457207592\n",
      "[Epoch] 269, [Loss] 0.14894351288232185\n",
      "[Epoch] 270, [Loss] 0.14476050281291136\n",
      "[Epoch] 271, [Loss] 0.14069886473435883\n",
      "[Epoch] 272, [Loss] 0.1367548947983213\n",
      "[Epoch] 273, [Loss] 0.13292501043457963\n",
      "[Epoch] 274, [Loss] 0.12920574602516374\n",
      "[Epoch] 275, [Loss] 0.12559374874644216\n",
      "[Epoch] 276, [Loss] 0.12208577457297587\n",
      "[Epoch] 277, [Loss] 0.11867868443564501\n",
      "[Epoch] 278, [Loss] 0.11536944052876114\n",
      "[Epoch] 279, [Loss] 0.11215510275842806\n",
      "[Epoch] 280, [Loss] 0.10903282532777976\n",
      "[Epoch] 281, [Loss] 0.1059998534520621\n",
      "[Epoch] 282, [Loss] 0.10305352019895463\n",
      "[Epoch] 283, [Loss] 0.10019124344939424\n",
      "[Epoch] 284, [Loss] 0.09741052297240384\n",
      "[Epoch] 285, [Loss] 0.09470893761085081\n",
      "[Epoch] 286, [Loss] 0.09208414257286386\n",
      "[Epoch] 287, [Loss] 0.08953386682428917\n",
      "[Epoch] 288, [Loss] 0.08705591057907539\n",
      "[Epoch] 289, [Loss] 0.08464814288220082\n",
      "[Epoch] 290, [Loss] 0.08230849928313973\n",
      "[Epoch] 291, [Loss] 0.08003497959429429\n",
      "[Epoch] 292, [Loss] 0.07782564573263903\n",
      "[Epoch] 293, [Loss] 0.07567861964006047\n",
      "[Epoch] 294, [Loss] 0.07359208128014431\n",
      "[Epoch] 295, [Loss] 0.07156426670781149\n",
      "[Epoch] 296, [Loss] 0.06959346620872585\n",
      "[Epoch] 297, [Loss] 0.06767802250647437\n",
      "[Epoch] 298, [Loss] 0.06581632903426227\n",
      "[Epoch] 299, [Loss] 0.06400682826837563\n",
      "[Epoch] 300, [Loss] 0.06224801012193741\n",
      "[Epoch] 301, [Loss] 0.06053841039541199\n",
      "[Epoch] 302, [Loss] 0.05887660928267008\n",
      "[Epoch] 303, [Loss] 0.05726122992972661\n",
      "[Epoch] 304, [Loss] 0.05569093704433228\n",
      "[Epoch] 305, [Loss] 0.05416443555506851\n",
      "[Epoch] 306, [Loss] 0.05268046931664069\n",
      "[Epoch] 307, [Loss] 0.051237819861168404\n",
      "[Epoch] 308, [Loss] 0.04983530519258933\n",
      "[Epoch] 309, [Loss] 0.04847177862317743\n",
      "[Epoch] 310, [Loss] 0.04714612765015439\n",
      "[Epoch] 311, [Loss] 0.04585727287102216\n",
      "[Epoch] 312, [Loss] 0.04460416693659599\n",
      "[Epoch] 313, [Loss] 0.04338579353919577\n",
      "[Epoch] 314, [Loss] 0.042201166436413105\n",
      "[Epoch] 315, [Loss] 0.04104932850672881\n",
      "[Epoch] 316, [Loss] 0.03992935083877607\n",
      "[Epoch] 317, [Loss] 0.03884033185016873\n",
      "[Epoch] 318, [Loss] 0.03778139643651109\n",
      "[Epoch] 319, [Loss] 0.03675169514899708\n",
      "[Epoch] 320, [Loss] 0.03575040339974513\n",
      "[Epoch] 321, [Loss] 0.0347767206930762\n",
      "[Epoch] 322, [Loss] 0.033829869883078734\n",
      "[Epoch] 323, [Loss] 0.032909096455287244\n",
      "[Epoch] 324, [Loss] 0.032013667832472864\n",
      "[Epoch] 325, [Loss] 0.031142872703150144\n",
      "[Epoch] 326, [Loss] 0.030296020372040166\n",
      "[Epoch] 327, [Loss] 0.029472440132150717\n",
      "[Epoch] 328, [Loss] 0.028671480657059396\n",
      "[Epoch] 329, [Loss] 0.027892509413204564\n",
      "[Epoch] 330, [Loss] 0.027134912091152954\n",
      "[Epoch] 331, [Loss] 0.0263980920552728\n",
      "[Epoch] 332, [Loss] 0.025681469811252383\n",
      "[Epoch] 333, [Loss] 0.024984482490744926\n",
      "[Epoch] 334, [Loss] 0.024306583352449646\n",
      "[Epoch] 335, [Loss] 0.023647241299308855\n",
      "[Epoch] 336, [Loss] 0.023005940411034268\n",
      "[Epoch] 337, [Loss] 0.022382179491582506\n",
      "[Epoch] 338, [Loss] 0.021775471630816383\n",
      "[Epoch] 339, [Loss] 0.02118534378025604\n",
      "[Epoch] 340, [Loss] 0.0206113363421223\n",
      "[Epoch] 341, [Loss] 0.020053002771226312\n",
      "[Epoch] 342, [Loss] 0.01950990918970575\n",
      "[Epoch] 343, [Loss] 0.01898163401317279\n",
      "[Epoch] 344, [Loss] 0.018467767589408126\n",
      "[Epoch] 345, [Loss] 0.01796791184739511\n",
      "[Epoch] 346, [Loss] 0.017481679958061568\n",
      "[Epoch] 347, [Loss] 0.017008696004953465\n",
      "[Epoch] 348, [Loss] 0.016548594665435908\n",
      "[Epoch] 349, [Loss] 0.016101020901592933\n",
      "[Epoch] 350, [Loss] 0.015665629660584535\n",
      "[Epoch] 351, [Loss] 0.015242085584304852\n",
      "[Epoch] 352, [Loss] 0.014830062727976144\n",
      "[Epoch] 353, [Loss] 0.014429244287127482\n",
      "[Epoch] 354, [Loss] 0.014039322333064564\n",
      "[Epoch] 355, [Loss] 0.013659997556438997\n",
      "[Epoch] 356, [Loss] 0.013290979018273252\n",
      "[Epoch] 357, [Loss] 0.012931983909078595\n",
      "[Epoch] 358, [Loss] 0.012582737314625883\n",
      "[Epoch] 359, [Loss] 0.012242971989098428\n",
      "[Epoch] 360, [Loss] 0.01191242813530702\n",
      "[Epoch] 361, [Loss] 0.01159085319087731\n",
      "[Epoch] 362, [Loss] 0.01127800162148701\n",
      "[Epoch] 363, [Loss] 0.010973634719756072\n",
      "[Epoch] 364, [Loss] 0.010677520410567904\n",
      "[Epoch] 365, [Loss] 0.010389433061864592\n",
      "[Epoch] 366, [Loss] 0.010109153301292468\n",
      "[Epoch] 367, [Loss] 0.009836467838020684\n",
      "[Epoch] 368, [Loss] 0.009571169290162876\n",
      "[Epoch] 369, [Loss] 0.009313056017082957\n",
      "[Epoch] 370, [Loss] 0.009061931956612434\n",
      "[Epoch] 371, [Loss] 0.00881760646724353\n",
      "[Epoch] 372, [Loss] 0.008579894174823985\n",
      "[Epoch] 373, [Loss] 0.008348614823711971\n",
      "[Epoch] 374, [Loss] 0.00812359313246308\n",
      "[Epoch] 375, [Loss] 0.007904658653559445\n",
      "[Epoch] 376, [Loss] 0.0076916456373512555\n",
      "[Epoch] 377, [Loss] 0.007484392899878247\n",
      "[Epoch] 378, [Loss] 0.007282743694551272\n",
      "[Epoch] 379, [Loss] 0.0070865455876566045\n",
      "[Epoch] 380, [Loss] 0.006895650337339758\n",
      "[Epoch] 381, [Loss] 0.006709913776118169\n",
      "[Epoch] 382, [Loss] 0.006529195696924396\n",
      "[Epoch] 383, [Loss] 0.006353359742229384\n",
      "[Epoch] 384, [Loss] 0.006182273296546437\n",
      "[Epoch] 385, [Loss] 0.0060158073818430535\n",
      "[Epoch] 386, [Loss] 0.005853836556227548\n",
      "[Epoch] 387, [Loss] 0.005696238815192479\n",
      "[Epoch] 388, [Loss] 0.005542895496034389\n",
      "[Epoch] 389, [Loss] 0.00539369118477783\n",
      "[Epoch] 390, [Loss] 0.0052485136258434125\n",
      "[Epoch] 391, [Loss] 0.0051072536342504\n",
      "[Epoch] 392, [Loss] 0.004969805010492578\n",
      "[Epoch] 393, [Loss] 0.00483606445750218\n",
      "[Epoch] 394, [Loss] 0.004705931500369516\n",
      "[Epoch] 395, [Loss] 0.00457930840803198\n",
      "[Epoch] 396, [Loss] 0.004456100117317781\n",
      "[Epoch] 397, [Loss] 0.004336214159202269\n",
      "[Epoch] 398, [Loss] 0.004219560586985042\n",
      "[Epoch] 399, [Loss] 0.004106051906671441\n",
      "[Epoch] 400, [Loss] 0.003995603009189308\n",
      "[Epoch] 401, [Loss] 0.0038881311045949195\n",
      "[Epoch] 402, [Loss] 0.003783555658101498\n",
      "[Epoch] 403, [Loss] 0.0036817983279289783\n",
      "[Epoch] 404, [Loss] 0.003582782904889684\n",
      "[Epoch] 405, [Loss] 0.003486435253642048\n",
      "[Epoch] 406, [Loss] 0.003392683255676875\n",
      "[Epoch] 407, [Loss] 0.00330145675378555\n",
      "[Epoch] 408, [Loss] 0.0032126874982458613\n",
      "[Epoch] 409, [Loss] 0.00312630909431347\n",
      "[Epoch] 410, [Loss] 0.0030422569513458555\n",
      "[Epoch] 411, [Loss] 0.002960468233277439\n",
      "[Epoch] 412, [Loss] 0.0028808818105156486\n",
      "[Epoch] 413, [Loss] 0.0028034382130820326\n",
      "[Epoch] 414, [Loss] 0.002728079585188439\n",
      "[Epoch] 415, [Loss] 0.002654749641035676\n",
      "[Epoch] 416, [Loss] 0.0025833936217924958\n",
      "[Epoch] 417, [Loss] 0.00251395825379118\n",
      "[Epoch] 418, [Loss] 0.002446391707950852\n",
      "[Epoch] 419, [Loss] 0.002380643560240453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch] 420, [Loss] 0.002316664753244394\n",
      "[Epoch] 421, [Loss] 0.00225440755892313\n",
      "[Epoch] 422, [Loss] 0.0021938255422496943\n",
      "[Epoch] 423, [Loss] 0.00213487352583907\n",
      "[Epoch] 424, [Loss] 0.0020775075557536568\n",
      "[Epoch] 425, [Loss] 0.0020216848680626124\n",
      "[Epoch] 426, [Loss] 0.0019673638563827847\n",
      "[Epoch] 427, [Loss] 0.0019145040403567722\n",
      "[Epoch] 428, [Loss] 0.0018630660349506604\n",
      "[Epoch] 429, [Loss] 0.0018130115206012314\n",
      "[Epoch] 430, [Loss] 0.00176430321425589\n",
      "[Epoch] 431, [Loss] 0.0017169048410772343\n",
      "[Epoch] 432, [Loss] 0.0016707811070722992\n",
      "[Epoch] 433, [Loss] 0.001625897672380455\n",
      "[Epoch] 434, [Loss] 0.0015822211253082076\n",
      "[Epoch] 435, [Loss] 0.001539718957138038\n",
      "[Epoch] 436, [Loss] 0.0014983595375331587\n",
      "[Epoch] 437, [Loss] 0.0014581120907002627\n",
      "[Epoch] 438, [Loss] 0.0014189466721789392\n",
      "[Epoch] 439, [Loss] 0.001380834146244657\n",
      "[Epoch] 440, [Loss] 0.0013437461639590133\n",
      "[Epoch] 441, [Loss] 0.0013076551418166834\n",
      "[Epoch] 442, [Loss] 0.001272534240951096\n",
      "[Epoch] 443, [Loss] 0.0012383573470010623\n",
      "[Epoch] 444, [Loss] 0.0012050990503588623\n",
      "[Epoch] 445, [Loss] 0.0011727346271401765\n",
      "[Epoch] 446, [Loss] 0.0011412400205703267\n",
      "[Epoch] 447, [Loss] 0.0011105918228709714\n",
      "[Epoch] 448, [Loss] 0.0010807672577300203\n",
      "[Epoch] 449, [Loss] 0.001051744163156114\n",
      "[Epoch] 450, [Loss] 0.0010235009748289531\n",
      "[Epoch] 451, [Loss] 0.0009960167099627819\n",
      "[Epoch] 452, [Loss] 0.0009692709515153311\n",
      "[Epoch] 453, [Loss] 0.0009432438328864764\n",
      "[Epoch] 454, [Loss] 0.0009179160230328735\n",
      "[Epoch] 455, [Loss] 0.0008932687119665135\n",
      "[Epoch] 456, [Loss] 0.0008692835966478\n",
      "[Epoch] 457, [Loss] 0.0008459428673013668\n",
      "[Epoch] 458, [Loss] 0.0008232291940371059\n",
      "[Epoch] 459, [Loss] 0.0008011257139302314\n",
      "[Epoch] 460, [Loss] 0.0007796160183325728\n",
      "[Epoch] 461, [Loss] 0.0007586841406301584\n",
      "[Epoch] 462, [Loss] 0.0007383145443096272\n",
      "[Epoch] 463, [Loss] 0.0007184921113014226\n",
      "[Epoch] 464, [Loss] 0.0006992021306894471\n",
      "[Epoch] 465, [Loss] 0.0006804302877285611\n",
      "[Epoch] 466, [Loss] 0.0006621626531178497\n",
      "[Epoch] 467, [Loss] 0.0006443856726119246\n",
      "[Epoch] 468, [Loss] 0.0006270861568855411\n",
      "[Epoch] 469, [Loss] 0.0006102512716732807\n",
      "[Epoch] 470, [Loss] 0.0005938685282118763\n",
      "[Epoch] 471, [Loss] 0.0005779257738863363\n",
      "[Epoch] 472, [Loss] 0.0005624111831760049\n",
      "[Epoch] 473, [Loss] 0.0005473132488183383\n",
      "[Epoch] 474, [Loss] 0.0005326207732226418\n",
      "[Epoch] 475, [Loss] 0.0005183228601444343\n",
      "[Epoch] 476, [Loss] 0.000504408906508385\n",
      "[Epoch] 477, [Loss] 0.0004908685945391838\n",
      "[Epoch] 478, [Loss] 0.0004776918840553827\n",
      "[Epoch] 479, [Loss] 0.00046486900497928535\n",
      "[Epoch] 480, [Loss] 0.0004523904500648095\n",
      "[Epoch] 481, [Loss] 0.00044024696781597714\n",
      "[Epoch] 482, [Loss] 0.0004284295555731124\n",
      "[Epoch] 483, [Loss] 0.0004169294528204271\n",
      "[Epoch] 484, [Loss] 0.0004057381346693183\n",
      "[Epoch] 485, [Loss] 0.000394847305480421\n",
      "[Epoch] 486, [Loss] 0.00038424889271562686\n",
      "[Epoch] 487, [Loss] 0.00037393504091993594\n",
      "[Epoch] 488, [Loss] 0.00036389810585979573\n",
      "[Epoch] 489, [Loss] 0.00035413064885141793\n",
      "[Epoch] 490, [Loss] 0.0003446254312061654\n",
      "[Epoch] 491, [Loss] 0.0003353754088694088\n",
      "[Epoch] 492, [Loss] 0.0003263737271412265\n",
      "[Epoch] 493, [Loss] 0.00031761371562830185\n",
      "[Epoch] 494, [Loss] 0.00030908888323673045\n",
      "[Epoch] 495, [Loss] 0.00030079291336147475\n",
      "[Epoch] 496, [Loss] 0.0002927196591966021\n",
      "[Epoch] 497, [Loss] 0.0002848631391418448\n",
      "[Epoch] 498, [Loss] 0.00027721753239392274\n",
      "[Epoch] 499, [Loss] 0.0002697771745769694\n",
      "loss曲线图已保存到loss.png文件\n",
      "对每张图片进行识别\n",
      "图像[0]得分类结果是:[-0.0009877434751461062]\n",
      "图像[1]得分类结果是:[0.9984347477014653]\n",
      "图像[2]得分类结果是:[2.002552871969043]\n",
      "图像[3]得分类结果是:[3.0104500983169413]\n",
      "图像[4]得分类结果是:[4.000093848566428]\n",
      "图像[5]得分类结果是:[4.995469344655432]\n",
      "图像[6]得分类结果是:[6.009978631120288]\n",
      "图像[7]得分类结果是:[6.999928548544891]\n",
      "图像[8]得分类结果是:[7.983288640253773]\n",
      "图像[9]得分类结果是:[9.00255780584279]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 先对模型进行训练\n",
    "    image_data, image_label = generate_data()\n",
    "\n",
    "    # 放大生成的图片\n",
    "    image_data = [bin2gray(x) for x in image_data]\n",
    "\n",
    "    num_sample = len(image_data)\n",
    "    num_feat = get_feature(image_data[0]).flatten().shape[0]\n",
    "    learning_rate = 1e-9\n",
    "    num_epoch = 500\n",
    "    device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n",
    "    model = LinearModel(in_dim=num_feat, out_dim=1).to(device)\n",
    "    train_model(model, image_data, image_label, max_epoch=num_epoch, lr=learning_rate, device=device)\n",
    "\n",
    "    print(\"对每张图片进行识别\")\n",
    "    for i in range(0, num_sample):\n",
    "        x = image_data[i]\n",
    "        # 对当前图片提取特征\n",
    "        feature = get_feature(x)\n",
    "        # 对提取到得特征进行分类\n",
    "        y = inference(feature, model, device=device)\n",
    "        # 打印出分类结果\n",
    "        print(\"图像[%s]得分类结果是:[%s]\" % (i, y.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
